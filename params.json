{
  "name": "Scrapper for the e-commerce sites",
  "tagline": "Web scrapper for fetching data from the e-commerce sites",
  "body": "<h1>Question Answering System for e­commerce sites</h1> \r\n \r\n<h3>Abstract </h3>\r\n---\r\n<p>These days most of the shopping is online with the growth of e­commerce. In this \r\nscenario, a customer or a user would want to know about a particular product before buying it . \r\nA customer service provider answers questions posed by users going through the product, \r\npricing and personal information of which they have access to. So, our project is to build a \r\nquestion answering system that would answer products­related questions of the users. Through \r\nthis project we would like to automate the task performed by customer service providers. \r\n</p>\r\n \r\n \r\n<h3>Project Scope</h3>\r\n ---\r\n<p>On a broad level the project aims to take a sentence as an input and extracts the aspect \r\nterm form it, and tries to use a simple pattern matching algorithm to retrieve the relevant \r\nanswers from the accessible data.\r\nThe Scope can be divided into the following levels:  \r\n1. Data representation using appropriate data structures. \r\n2. Aspect Term detection in the query. \r\n3. Identify the right fields in the constructed data structure of the available data. \r\n4. Generate a sentence asking the customer to provide the required  information, if \r\nanything is missing. \r\n5. keeping track of the information in previous question, so that the context doesn't get lost. \r\n6. Classification of queries into bins based on the type of response like descriptive, yes/no \r\nquestion, etc. \r\n7. Ranking the relevant responses.\r\n</p>\r\n \r\n<h3>Proposed Approach : </h3>\r\n ---\r\n● Removing stop words: Stop words are the words which appear frequently in the query but provide less meaning in\r\n  identifying the important content of the document such as ‘a’, ‘an’, ‘the’,  etc. \r\n\r\n● Stemming: Word stemming is the process of removing prefixes and suffixes of each word.  \r\n\r\n● We then identify the tokens which define many of the possible domain questions and answerable token keywords \r\n  which enable our system to search questions more efficiently. (​ Aspect term extraction​ ) \r\n\r\n● The system will search for the term that is found in Step 3 and its associative word found in Step 2. If the \r\n  user asks the question: “What is the warranty period for a Videocon TV model: VIDCN 12345”. Then the system \r\n  will search for the domain ‘TV’, then sub­domain: ‘Videocon’ And then for model number that is in the user \r\n  query. \r\n     1. If the user’s question is incomplete, then our system will prompt for the missing information. \r\n     2. System will auto generate questions depending on the previous questions. If the user asks for television \r\n        and warranty period’ in the previous queries then our system will ask further questions like ’warranty  \r\n        period range’ or ‘would you interested in screen size’, etc.  \r\n\r\n<h3>Tools/Technologies to be used : </h3>\r\n---\r\n\r\n1. Scrapy ­ For crawling and collecting data.  \r\n2. Stanford’s Aspect Term Tool ­ For extracting the aspect term from the query.\r\n3. Stanford NLP  Parser & POS­Tagger \r\n4. Natural Language Toolkit (NLTK) \r\n5. Python",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}